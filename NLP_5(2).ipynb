{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cd5fd2-9bdc-4eaa-a483-2157639fac9b",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3dfa83-8eb8-4f54-be26-2698bb7c5091",
   "metadata": {},
   "source": [
    "Task 0. Build an N-gram language model based on some corpus.\n",
    "\n",
    "Завдання 0: Побудова N-грам моделі\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47f54d9-be9d-40cc-9cad-387ff16a34fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Біграми та їхні частоти:\n",
      "(natural, language): 1\n",
      "(language, processing): 1\n",
      "(processing, nlp): 1\n",
      "(nlp, is): 1\n",
      "(nlp, helps): 1\n",
      "(is, a): 1\n",
      "(is, rapidly): 1\n",
      "(a, field): 1\n",
      "(field, of): 1\n",
      "(field, is): 1\n",
      "(of, artificial): 1\n",
      "(of, deep): 1\n",
      "(artificial, intelligence): 1\n",
      "(helps, machines): 1\n",
      "(machines, understand): 1\n",
      "(understand, and): 1\n",
      "(and, generate): 1\n",
      "(generate, human): 1\n",
      "(human, language): 1\n",
      "(this, field): 1\n",
      "(rapidly, evolving): 1\n",
      "(evolving, with): 1\n",
      "(with, the): 1\n",
      "(the, help): 1\n",
      "(help, of): 1\n",
      "(deep, learning): 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "# Вхідний текстовий корпус (невеликий приклад)\n",
    "corpus = \"\"\"\n",
    "    Natural language processing (NLP) is a field of artificial intelligence. \n",
    "    NLP helps machines understand and generate human language.\n",
    "    This field is rapidly evolving with the help of deep learning.\n",
    "\"\"\"\n",
    "\n",
    "# Оброляємо текст\n",
    "def preprocess(text):\n",
    "    text = text.lower()                   # Переводимо у нижній регістр\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Видаляємо розділові знаки\n",
    "    sentences = text.strip().split(\"\\n\")  # Розбиваємо на речення за рядками\n",
    "    tokenized = [sentence.strip().split() for sentence in sentences if sentence.strip()]  # Токенізуємо\n",
    "    return tokenized\n",
    "\n",
    "# Застосовуємо попередню обробку до корпусу\n",
    "sentences = preprocess(corpus)\n",
    "\n",
    "# Побудова біграмної моделі (використовуємо defaultdict(Counter) для підрахунку частот)\n",
    "bigrams = defaultdict(Counter)\n",
    "\n",
    "# Проходимося по кожному реченню та збираємо пари (слово, наступне слово)\n",
    "for sentence in sentences:\n",
    "    for i in range(len(sentence) - 1):\n",
    "        w1, w2 = sentence[i], sentence[i+1]\n",
    "        bigrams[w1][w2] += 1  # Збільшуємо лічильник для пари слів\n",
    "\n",
    "# 4. Виведення результатів\n",
    "# Виводимо всі знайдені біграми та кількість їх появ у тексті\n",
    "print(\"Біграми та їхні частоти:\")\n",
    "for w1 in bigrams:\n",
    "    for w2 in bigrams[w1]:\n",
    "        print(f\"({w1}, {w2}): {bigrams[w1][w2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6915ad8-4417-4fd0-aae1-fbd06f6ab971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2965c94b-39bf-4b53-a55b-64f4700e6108",
   "metadata": {},
   "source": [
    "Task 1. Compare bi- and tri-gram models\n",
    "\n",
    "Завдання 1. Порівняйте біграми (2-грамну модель) і триграми (3-грамну модель)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69cdaea-2cd9-4d58-9eda-a58a38cf5efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Триграми та їхні частоти:\n",
      "(natural, language, processing): 1\n",
      "(language, processing, nlp): 1\n",
      "(processing, nlp, is): 1\n",
      "(nlp, is, a): 1\n",
      "(is, a, field): 1\n",
      "(a, field, of): 1\n",
      "(field, of, artificial): 1\n",
      "(of, artificial, intelligence): 1\n",
      "(nlp, helps, machines): 1\n",
      "(helps, machines, understand): 1\n",
      "(machines, understand, and): 1\n",
      "(understand, and, generate): 1\n",
      "(and, generate, human): 1\n",
      "(generate, human, language): 1\n",
      "(this, field, is): 1\n",
      "(field, is, rapidly): 1\n",
      "(is, rapidly, evolving): 1\n",
      "(rapidly, evolving, with): 1\n",
      "(evolving, with, the): 1\n",
      "(with, the, help): 1\n",
      "(the, help, of): 1\n",
      "(help, of, deep): 1\n",
      "(of, deep, learning): 1\n"
     ]
    }
   ],
   "source": [
    "# Побудова триграмної моделі\n",
    "trigrams = defaultdict(Counter)\n",
    "for sentence in sentences:\n",
    "    for i in range(len(sentence) - 2):\n",
    "        w1, w2, w3 = sentence[i], sentence[i+1], sentence[i+2]\n",
    "        trigrams[(w1, w2)][w3] += 1\n",
    "\n",
    "print(\"\\nТриграми та їхні частоти:\")\n",
    "for (w1, w2) in trigrams:\n",
    "    for w3 in trigrams[(w1, w2)]:\n",
    "        print(f\"({w1}, {w2}, {w3}): {trigrams[(w1, w2)][w3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c386636-4d4d-4b1e-849a-648d4153d1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5806e883-6ad3-475c-95eb-d6f0dd750afe",
   "metadata": {},
   "source": [
    "Task 2. Apply interpolation/backoff to your model so that it can better handle unknown words/prompts.\n",
    "\n",
    "Завдання 2. Застосуйте інтерполяцію або \"відкат\" (backoff) до вашої моделі, щоб краще обробляти невідомі слова/підказки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88791ade-fd50-4eff-a5b2-936b9802ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Інтерпольовані ймовірності для слова після 'this field':\n",
      "is: 0.7569\n",
      "evolving: 0.0034\n",
      "deep: 0.0034\n",
      "learning: 0.0034\n",
      "unknownword: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sentence in sentences:\n",
    "    for i in range(len(sentence)):\n",
    "        unigrams[sentence[i]] += 1\n",
    "        if i < len(sentence) - 1:\n",
    "            bigrams[sentence[i]][sentence[i+1]] += 1\n",
    "        if i < len(sentence) - 2:\n",
    "            trigrams[(sentence[i], sentence[i+1])][sentence[i+2]] += 1\n",
    "# 4. Функція з лінійною інтерполяцією\n",
    "# Використовуємо ваги для комбінації ймовірностей з уніграм, біграм, триграм\n",
    "\n",
    "def interpolated_probability(w1, w2, w3, l1=0.1, l2=0.3, l3=0.6):\n",
    "    unigram_prob = unigrams[w3] / sum(unigrams.values()) if w3 in unigrams else 0\n",
    "    bigram_prob = bigrams[w2][w3] / sum(bigrams[w2].values()) if w2 in bigrams and w3 in bigrams[w2] else 0\n",
    "    trigram_prob = trigrams[(w1, w2)][w3] / sum(trigrams[(w1, w2)].values()) if (w1, w2) in trigrams and w3 in trigrams[(w1, w2)] else 0\n",
    "    return l1 * unigram_prob + l2 * bigram_prob + l3 * trigram_prob\n",
    "\n",
    "# 5. Приклад використання\n",
    "# Це дозволяє оцінити, яке слово найбільш ймовірне після вказаного контексту\n",
    "context = (\"this\", \"field\")\n",
    "candidates = [\"is\", \"evolving\", \"deep\", \"learning\", \"unknownword\"]\n",
    "\n",
    "print(\"\\nІнтерпольовані ймовірності для слова після 'this field':\")\n",
    "for word in candidates:\n",
    "    prob = interpolated_probability(context[0], context[1], word)\n",
    "    print(f\"{word}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0bf5bd-213d-453c-a15d-877c5ec41a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dcb4b39-fe2f-4b0e-86cc-4897bb80fd8e",
   "metadata": {},
   "source": [
    "Task 3. Use this model to build sentences. Meaning, for a prompt consisting of words p1,...,pn, it should produce a continuation w1,...,wk.\n",
    "\n",
    "Завдання 3. Використовуйте цю модель для побудови речень. Тобто, для підказки, що складається зі слів p1,...,pn, модель повинна передбачити продовження wn,…,wk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f641155-8968-42fb-9d60-1654d7d50ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Згенероване речення:\n",
      "this field is rapidly evolving with the help of deep learning language\n"
     ]
    }
   ],
   "source": [
    "# Генерація речення з підказки (prompt)\n",
    "def generate_sentence(prompt, max_words=10):\n",
    "    generated = prompt[:]\n",
    "    for _ in range(max_words):\n",
    "        if len(generated) < 2:\n",
    "            break\n",
    "        w1, w2 = generated[-2], generated[-1]\n",
    "        candidates = list(unigrams.keys())\n",
    "        # Знаходимо слово з найбільшою ймовірністю\n",
    "        next_word = max(candidates, key=lambda w: interpolated_probability(w1, w2, w))\n",
    "        generated.append(next_word)\n",
    "    return \" \".join(generated)\n",
    "\n",
    "# 6. Приклад побудови речення\n",
    "prompt = [\"this\", \"field\"]\n",
    "generated_sentence = generate_sentence(prompt)\n",
    "print(\"\\nЗгенероване речення:\")\n",
    "print(generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65126c4-9eea-4c10-91c7-8b34705e744d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
